# 数据预处理(processing)

## 什么是数据预处理

通过`特定的统计方法（数学方法)`,将数据转换成`算法要求的数据`。

## 数据预处理有哪些方法

数值型数据：

- 标准缩放
  - 归一化(MinMaxScaler)
  - 标准化(StanderScaler)
- 缺失值

类别型数据：one-hot编码

时间类数据：时间的切分

## 归一化

![归一化数学公式](https://raw.githubusercontent.com/zhusheng/blog/master/ml/07.png)

归一化的目的就是将`原始数据`映射到`0～1`之间(`默认`)，当然我们也可以指定映射到2～3之间等。

示例如下：
![归一化示例](https://raw.githubusercontent.com/zhusheng/blog/master/ml/08.png)

归一化的特点：
注意在特定场景下最大值最小值是变化的，另外，最大值与最小值非常容易受异常点影响，所以这种方法鲁棒性较差，只适合传统精确小数据场景。所以归一化使用的非常少，一般使用标准化。

## 标准化

![标准化数学公式](https://raw.githubusercontent.com/zhusheng/blog/master/ml/09.png)

方差反应的是数据的集中情况，数据越集中方差越小。

我们以一种极端的例子说明，当方差为0的时候，所有的特征值都是一样的，样本集中在一起。在实际数据中，基本不会出现方差为0的情况。如果数据越集中，方差越小，反之越大。

我们综合比较归一化和标准化：

对于归一化来说，如果数据出现异常点，影响了最大值和最小值，那么结果显然也会有很大的差异；
对于标准化来说，如果数据出现异常点，由于具有一定的数据量，个别的异常点对于平均值的影响并不大，从而方差的改变较小，它反应的是数据的集中情况。

### 适合场景

在已有样本足够多的情况下比较稳定，适合现代嘈杂大数据场景。

并不是所有的算法都需要归一化、标准化。

## 缺失值处理

在特征值中，会存在缺失值的情况，我们有删除和插补两种处理方式，一般都是采用插补的方式。

- 删除。如果每列或者行数据缺失值达到一定的比例，建议放弃整行或者整列。
- 插补。可以通过缺失值所在的每行或者每列的平均值、中位数来填充。

说明：
numpy的数组中，可以使用np.nan、np.NaN来代替缺失值，属于float类型。如果原始数据中有缺失值，我们可以先替换为NaN,然后转换为np.NaN。


