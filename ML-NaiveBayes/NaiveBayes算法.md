# NaiveBayes算法

## NaiveBayes算法原理

定义
> `朴素贝叶斯算法`是基于`贝叶斯定理`与`特征条件独立假设`的`分类方法`。

算法介绍
> `最为广泛的两种分类模型`是`决策树模型(Decision Tree Model)`和`朴素贝叶斯模型（Naive Bayesian Model，NBM）`。和决策树模型相比，`朴素贝叶斯分类器(Naive Bayes Classifier,或 NBC)`发源于古典数学理论，有着坚实的数学基础，以及稳定的分类效率。同时，NBC模型所需估计的参数很少，对缺失数据不太敏感，算法也比较简单。理论上，NBC模型与其他分类方法相比具有最小的误差率。但是实际上并非总是如此，这是因为`NBC模型假设属性之间相互独立，这个假设在实际应用中往往是不成立的`，这给NBC模型的正确分类带来了一定影响。

算法原理
> 朴素贝叶斯分类（NBC）是以贝叶斯定理为基础并且假设特征条件之间相互独立的方法，先通过已给定的训练集，`以特征词之间独立作为前提假设`，`学习从输入到输出的联合概率分布`，再基于学习到的模型，输入  求出使得后验概率最大的输出。

## NaiveBayes算法优缺点

优点：

- 朴素贝叶斯模型发源于古典数学理论，有稳定的分类效率。
- 对缺失数据不太敏感，算法也比较简单，常用于文本分类。
- 分类准确度高，速度快。

缺点：

- 要知道先验概率P(F1,F2,…|C)，因此在某些时候会由于假设的先验模型的原因导致预测效果不佳。简单理解就是`朴素贝叶斯算法的前提就是要“朴素”`，也就是`特征之间互相独立`，如果特征之间有关联性，分类效果就会比较差。

早起的垃圾邮件分类就是使用朴素贝叶斯进行分类的，现在神经网络的分类效果比朴素贝叶斯效果更好。

## NaiveBayes算法数学公式

![朴素贝叶斯公式](https://raw.githubusercontent.com/zhusheng/blog/master/ml/14.png)
![朴素贝叶斯公式2](https://raw.githubusercontent.com/zhusheng/blog/master/ml/15.png)

## NaiveBayes算法案例，数学原理计算

样本数据集
![朴素贝叶斯公式2](https://raw.githubusercontent.com/zhusheng/blog/master/ml/16.png)

计算过程如下：
![计算过程](https://raw.githubusercontent.com/zhusheng/blog/master/ml/17.png)

在进行文章分类统计的时候，P(C|F1，F2，F3) = P(F1,F2,F3|C) * P(C)，不然计算的结果概率大于1；
我们计算属于娱乐的概率为0，这是不合理的，如果词频统计出现次数为0，结果概率都为0，这是不合理的。为了解决这个问题，我们引入了拉普拉斯平滑系数𝛂；

## NaiveBayes算法数据集

### fetch_20newsgroups数据集

我们使用的是`sklearn.datasets`内部集成的数据集`fetch_20newsgroups`API，首次调用的时候，我们也是需要去下载该数据集的。

该数据集是一个`新闻文章数据集`。